# -*- coding: utf-8 -*-
"""
MÃ³dulo para a aba "InteligÃªncia & PrevisÃ£o".
Inclui detecÃ§Ã£o de anomalias, previsÃ£o de volume, simulador de alertas e seguranÃ§a.
"""

import streamlit as st
import pandas as pd
import altair as alt
import log_analyzer as lam
from dashboard.caching import (
    cached_detect_volume_anomalies, 
    cached_detect_rare_patterns, 
    cached_generate_volume_forecast, 
    cached_detect_log_periodicity, 
    cached_analyze_security_threats, 
    cached_extract_latency_metrics, 
    cached_detect_bottlenecks, 
    cached_group_incidents, 
    cached_mask_sensitive_data
)

def render_ml_sub_tab(filtered_df, time_series_df, z_score_threshold, rarity_threshold, enable_masking):
    """Renderiza a sub-aba "Anomalias (ML)"."""
    st.header("ğŸ§  DetecÃ§Ã£o de Anomalias (Machine Learning)")
    st.markdown("Esta seÃ§Ã£o utiliza algoritmos estatÃ­sticos para identificar comportamentos fora do padrÃ£o.")

    col_vol, col_pat = st.columns(2)
    with col_vol:
        st.subheader("ğŸ“ˆ Anomalias de Volume")
        st.write(f"Detecta picos repentinos na quantidade de logs (Z-Score > {z_score_threshold}).")
        
        anomalies_df = cached_detect_volume_anomalies(filtered_df, z_score_threshold)
        if not anomalies_df.empty:
            st.error(f"Foram detectados {len(anomalies_df)} momentos de pico anÃ´malo.")
            st.dataframe(anomalies_df)
            
            # GrÃ¡fico de anomalias
            base = alt.Chart(time_series_df).encode(x='timestamp:T')
            line = base.mark_line().encode(y='count:Q')
            points = alt.Chart(anomalies_df).mark_circle(color='red', size=100).encode(
                x='timestamp:T',
                y='count:Q',
                tooltip=['timestamp', 'count']
            )
            st.altair_chart(line + points, use_container_width=True)
            
            # BotÃ£o de ExportaÃ§Ã£o de Anomalias
            csv_anomalies = anomalies_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ğŸ“¥ Baixar Anomalias de Volume (CSV)",
                data=csv_anomalies,
                file_name="anomalias_volume.csv",
                mime="text/csv", 
                help="Baixe a lista de anomalias de volume detectadas em formato CSV."
            )
        else:
            st.success("Nenhuma anomalia de volume detectada.")
    
    with col_pat:
        st.subheader("ğŸ¦„ PadrÃµes Raros (Rare Events)")
        st.write(f"Detecta mensagens de log com estrutura incomum (frequÃªncia < {rarity_threshold*100:.2f}%).")
        
        rare_logs_df = cached_detect_rare_patterns(filtered_df, rarity_threshold)
        if not rare_logs_df.empty:
            st.warning(f"Encontrados {len(rare_logs_df)} logs com padrÃµes raros.")
            st.dataframe(rare_logs_df[['timestamp', 'log_level', 'message']])
            
            # BotÃ£o de ExportaÃ§Ã£o de PadrÃµes Raros
            csv_rare = rare_logs_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ğŸ“¥ Baixar Logs Raros (CSV)",
                data=csv_rare,
                file_name="logs_raros.csv",
                mime="text/csv",
                help="Baixe a lista de padrÃµes de log raros detectados em formato CSV."
            )
        else:
            st.success("Nenhum padrÃ£o raro detectado.")

    st.markdown("---")
    st.subheader("ğŸ” AnÃ¡lise de Outliers (Tamanho da Mensagem)")
    st.info("Este grÃ¡fico ajuda a identificar logs anormalmente longos (ex: stack traces) ou curtos demais.")
    
    # Scatter Plot: Tamanho da Mensagem vs Tempo
    # OtimizaÃ§Ã£o: Amostragem se houver muitos pontos
    scatter_data = filtered_df if len(filtered_df) < 2000 else filtered_df.sample(2000)
    
    if not scatter_data.empty:
        scatter_chart = alt.Chart(scatter_data).mark_circle(size=60).encode(
            x=alt.X('timestamp:T', title='Tempo'),
            y=alt.Y('message_length:Q', title='Tamanho da Mensagem (caracteres)'),
            color=alt.Color('log_level', title='NÃ­vel'),
            tooltip=['timestamp', 'log_level', 'category', 'message_length', alt.Tooltip('message', title='Mensagem', format='.100s')]
        ).properties(
            title="DispersÃ£o: Tamanho da Mensagem vs Tempo"
        ).interactive()
        
        st.altair_chart(scatter_chart, use_container_width=True)
    else:
        st.info("Sem dados para anÃ¡lise de outliers.")
    
    st.markdown("---")
    st.subheader("ğŸ”” Agrupamento de Incidentes (AIOps)")
    st.write("Agrupa erros similares em incidentes Ãºnicos para evitar fadiga de alertas.")
    
    incidents = cached_group_incidents(filtered_df)
    if not incidents.empty:
        if enable_masking:
            incidents['example_message'] = cached_mask_sensitive_data(pd.DataFrame(incidents['example_message'], columns=['message']))['message']
        st.dataframe(incidents, use_container_width=True)
    else:
        st.success("Nenhum incidente agrupÃ¡vel encontrado nos logs filtrados (NÃ­veis: Error, Fail, Critical ou palavras-chave de erro).")

def render_forecast_sub_tab(filtered_df):
    """Renderiza a sub-aba "PrevisÃ£o (Forecast)"."""
    st.header("ğŸ”® PrevisÃ£o de Volume (Forecast)")
    st.markdown("Utiliza regressÃ£o linear para projetar a tendÃªncia do volume de logs para a prÃ³xima hora. Ãštil para **Capacity Planning**.")
    
    forecast_df, trend, slope = cached_generate_volume_forecast(filtered_df)
    if not forecast_df.empty:
        # MÃ©tricas
        col_f1, col_f2, col_f3 = st.columns(3)
        
        # Busca segura dos valores (evita erro de index se filtro vazio ou string diferente)
        hist_data = forecast_df[forecast_df['type'] == 'HistÃ³rico ğŸ“Š']
        pred_data = forecast_df[forecast_df['type'].astype(str).str.contains('PrevisÃ£o', na=False)]
        
        current_vol = hist_data['count'].iloc[-1] if not hist_data.empty else 0
        predicted_vol = pred_data['count'].iloc[-1] if not pred_data.empty else 0
        
        col_f1.metric("TendÃªncia Atual", trend)
        col_f2.metric("Volume Atual (p/ min)", f"{int(current_vol)}")
        col_f3.metric("PrevisÃ£o (+60 min)", f"{int(predicted_vol)}", delta=f"{int(predicted_vol - current_vol)}")
        
        # GrÃ¡fico
        st.subheader("ProjeÃ§Ã£o de TrÃ¡fego")
        
        chart_forecast = alt.Chart(forecast_df).mark_line().encode(
            x=alt.X('timestamp:T', title='Tempo'),
            y=alt.Y('count:Q', title='Volume de Logs'),
            color=alt.Color('type', title='Status', scale=alt.Scale(scheme='category20')),
            strokeDash=alt.condition(
                alt.datum.type != 'HistÃ³rico ğŸ“Š',
                alt.value([5, 5]),  # Linha tracejada para previsÃ£o
                alt.value([0])      # Linha sÃ³lida para histÃ³rico
            ),
            tooltip=['timestamp', 'count', 'type']
        ).interactive()
        
        st.altair_chart(chart_forecast, use_container_width=True)
        
        if slope > 0.1:
            st.warning("âš ï¸ AtenÃ§Ã£o: TendÃªncia de crescimento acentuada detectada. Verifique se hÃ¡ um inÃ­cio de incidente ou ataque DDoS.")
        elif slope < -0.1:
            st.info("ğŸ“‰ O volume de logs estÃ¡ diminuindo rapidamente.")
    else:
        st.warning("Dados insuficientes para gerar uma previsÃ£o confiÃ¡vel.")

    # --- FFT Periodicity ---
    st.markdown("---")
    st.subheader("ğŸ”„ AnÃ¡lise de Periodicidade (FFT)")
    st.markdown("Detecta padrÃµes repetitivos (ex: Cron Jobs, Health Checks) analisando o espectro de frequÃªncia dos logs.")
    
    periods = cached_detect_log_periodicity(filtered_df)
    
    if periods:
        st.success(f"Detectamos {len(periods)} padrÃ£o(Ãµes) cÃ­clico(s) relevante(s).")
        cols = st.columns(len(periods))
        for i, (period, strength) in enumerate(periods):
            with cols[i]:
                st.metric(
                    label=f"Ciclo #{i+1}",
                    value=f"A cada {period:.1f} min",
                    help=f"ForÃ§a do sinal (ConfianÃ§a): {strength*100:.1f}%"
                )
    else:
        duration_str = "N/A"
        if not filtered_df.empty and 'timestamp' in filtered_df.columns:
            duration = filtered_df['timestamp'].max() - filtered_df['timestamp'].min()
            duration_minutes = duration.total_seconds() / 60
            duration_str = f"{duration_minutes:.1f} min"
        
        st.info(f"Nenhuma periodicidade clara detectada.\n\n**DiagnÃ³stico:**\n- DuraÃ§Ã£o dos dados: {duration_str}\n- Sinal pode ser aperiÃ³dico (sem repetiÃ§Ãµes fixas).")

def render_alerts_sub_tab(filtered_df, enable_masking):
    """Renderiza a sub-aba "Simulador de Alertas"."""
    st.header("ğŸ”” Simulador de Alertas")
    st.markdown("Defina regras personalizadas para verificar quais logs disparariam alertas em um ambiente de produÃ§Ã£o.")
    
    col_rule1, col_rule2, col_rule3 = st.columns(3)
    
    with col_rule1:
        alert_latency = st.number_input("Regra: LatÃªncia Maior que (ms)", min_value=0, value=0, step=50, help="0 para desativar este filtro.", key="alert_latency_3")
    
    with col_rule2:
        alert_keyword = st.text_input("Regra: ContÃ©m Palavra-chave", placeholder="Ex: timeout, deadlock", help="Digite uma palavra ou frase que deve estar presente no log para disparar o alerta.")
    
    with col_rule3:
        # Usa raw_df para garantir que todos os nÃ­veis apareÃ§am, independente do filtro atual
        raw_df = st.session_state.get('raw_df')
        source_df = raw_df if raw_df is not None and not raw_df.empty else filtered_df
        
        all_levels = sorted(source_df['log_level'].unique())
        default_levels = [lvl for lvl in ['Error', 'Fail', 'Critical', 'Fatal'] if lvl in all_levels]
        alert_levels = st.multiselect("Regra: NÃ­veis de Log", options=all_levels, default=default_levels, help="Selecione quais nÃ­veis de log (ex: Error) devem ser considerados para o alerta.")
    
    # Recupera URL configurada (Oculta por seguranÃ§a)
    webhook_url = lam.get_setting("webhook_url", "")
    if webhook_url:
        st.info("Webhook do Teams configurado para Canal: Alert for Logs.")
    else:
        st.warning("Webhook do Teams nÃ£o configurado no sistema.")

    # BotÃµes lado a lado
    col_btn_sim, col_btn_test = st.columns([3, 1])

    with col_btn_sim:
        run_sim = st.button("Simular Regras de Alerta", help="Clique para verificar quais logs histÃ³ricos teriam disparado este alerta com as regras definidas.", use_container_width=True)
    
    with col_btn_test:
        run_test = st.button("ğŸ“¨ Testar ConexÃ£o", help="Envia uma mensagem de teste imediata para o Teams configurado.", use_container_width=True)

    if run_sim:
        # Salva URL se preenchida para uso futuro
        if webhook_url:
            lam.save_setting("webhook_url", webhook_url)

        # Se nenhum filtro for aplicado, avisa
        if alert_latency == 0 and not alert_keyword and not alert_levels:
            st.warning("Defina ao menos uma regra para simular.")
        else:
            # Usa filtered_df para simulaÃ§Ã£o no contexto atual
            triggered = lam.simulate_alerts(filtered_df, latency_threshold=alert_latency if alert_latency > 0 else None, keyword=alert_keyword, log_levels=alert_levels)
            
            if not triggered.empty:
                st.error(f"ğŸš¨ ALERTA DISPARADO! {len(triggered)} logs correspondem Ã s regras definidas.")
                
                # Aplica mascaramento se estiver ativado
                if enable_masking:
                    triggered_display = lam.mask_sensitive_data(triggered)
                else:
                    triggered_display = triggered

                # MÃ©tricas do Alerta
                col_a1, col_a2 = st.columns(2)
                col_a1.metric("Total de Disparos", len(triggered))
                if 'latency_ms' in triggered.columns:
                    max_lat = triggered['latency_ms'].max()
                    col_a2.metric("LatÃªncia MÃ¡xima Detectada", f"{max_lat} ms")
                
                # GrÃ¡fico de linha temporal dos alertas
                st.subheader("Disparos ao Longo do Tempo")
                alert_time_series = triggered.set_index('timestamp').resample('T').size().reset_index(name='count')
                
                alert_chart = alt.Chart(alert_time_series).mark_line(point=True, color='red').encode(
                    x=alt.X('timestamp:T', title='Tempo'),
                    y=alt.Y('count:Q', title='Quantidade de Alertas'),
                    tooltip=['timestamp:T', 'count:Q']
                ).interactive()
                
                st.altair_chart(alert_chart, use_container_width=True)

                # Tabela
                st.dataframe(triggered_display[['timestamp', 'log_level', 'source', 'message']], use_container_width=True)
                
                # Teste de Webhook
                if webhook_url:
                    if st.button("ğŸ“¨ Enviar Alerta de Teste para Webhook"):
                        msg_body = f"Foram detectados {len(triggered)} logs crÃ­ticos. LatÃªncia mÃ¡x: {triggered.get('latency_ms', pd.Series([0])).max()}ms."
                        response = lam.send_webhook_alert(webhook_url, msg_body)
                        if isinstance(response, str): st.error(response)
                        else: st.success(f"Alerta enviado com sucesso! (Status: {response.status_code})")
            else:
                st.success("âœ… Nenhum log dispararia este alerta com as regras atuais.")

    if run_test:
        if webhook_url:
            lam.save_setting("webhook_url", webhook_url)
            response = lam.send_webhook_alert(webhook_url, "Isso Ã© um teste de verificaÃ§Ã£o de conectividade.\n\nSe vocÃª recebeu esta mensagem, a integraÃ§Ã£o com o Dashboard de Logs estÃ¡ **OPERACIONAL**! âœ…", title="ğŸ”” Teste de ConexÃ£o Teams")
            
            if isinstance(response, str):
                st.error(response)
            elif response.status_code != 200:
                st.error(f"Erro {response.status_code}: {response.text}")
            else:
                st.toast("Mensagem de teste enviada!", icon="ğŸš€")
                st.info("Resposta do servidor Teams (cÃ³digo 200 OK):")
                st.code(response.text)
        else:
            st.warning("Por favor, insira uma URL de Webhook vÃ¡lida.")

def render_siem_sub_tab(filtered_df):
    """Renderiza a sub-aba "SeguranÃ§a (SIEM)"."""
    st.header("ğŸ›¡ï¸ AnÃ¡lise de SeguranÃ§a em Tempo Real")
    st.markdown("Monitoramento de IPs suspeitos e ameaÃ§as potenciais (Threat Intelligence simulada).")
    
    threats = cached_analyze_security_threats(filtered_df)
    if not threats.empty:
        col_kpi1, col_kpi2 = st.columns(2)
        with col_kpi1:
            st.metric("IPs CrÃ­ticos", len(threats[threats['status'] == 'ğŸ”´ CrÃ­tico']))
        with col_kpi2:
            st.metric("IPs Suspeitos", len(threats[threats['status'] == 'ğŸŸ¡ Suspeito']))
        
        st.subheader("Top IPs por Taxa de Erro")
        st.dataframe(threats)
        
        chart_threat = alt.Chart(threats).mark_circle(size=100).encode(
            x=alt.X('total_logs', title='Volume Total de Logs'),
            y=alt.Y('error_rate', title='Taxa de Erro (0-1)'),
            color='status',
            tooltip=['ip', 'total_logs', 'error_rate', 'status']
        ).interactive()
        st.altair_chart(chart_threat, use_container_width=True)
    else:
        st.info("Nenhum IP detectado nos logs para anÃ¡lise de seguranÃ§a.")

def render_latency_sub_tab(filtered_df):
    """Renderiza a sub-aba "Performance"."""
    st.header("â±ï¸ AnÃ¡lise AvanÃ§ada de LatÃªncia")
    st.markdown("VisualizaÃ§Ã£o estatÃ­stica do tempo de resposta extraÃ­do dos logs (padrÃ£o `duration=Xms`).")
    
    latency_df = cached_extract_latency_metrics(filtered_df)
    if not latency_df.empty:
        # CÃ¡lculos EstatÃ­sticos
        stats = latency_df['latency_ms'].describe(percentiles=[.5, .9, .95, .99])
        
        # KPIs
        l1, l2, l3, l4 = st.columns(4)
        l1.metric("MÃ©dia", f"{stats['mean']:.1f} ms")
        l2.metric("P95 (95% dos reqs)", f"{stats['95%']:.1f} ms", help="95% das requisiÃ§Ãµes sÃ£o mais rÃ¡pidas que este valor.")
        l3.metric("P99 (Cauda Longa)", f"{stats['99%']:.1f} ms", help="1% das requisiÃ§Ãµes mais lentas (outliers).")
        l4.metric("MÃ¡ximo", f"{stats['max']:.1f} ms")
        
        st.markdown("---")
        
        col_lat_1, col_lat_2 = st.columns(2)
        
        with col_lat_1:
            st.subheader("DistribuiÃ§Ã£o de LatÃªncia (Histograma)")
            hist = alt.Chart(latency_df).mark_bar().encode(
                x=alt.X('latency_ms:Q', bin=alt.Bin(maxbins=30), title='LatÃªncia (ms)'),
                y=alt.Y('count()', title='Contagem'),
                tooltip=['count()', alt.Tooltip('latency_ms', bin=True)]
            ).interactive()
            st.altair_chart(hist, use_container_width=True)
            
        with col_lat_2:
            st.subheader("LatÃªncia por Origem (Top 10)")
            # Agrupa por source e pega a mÃ©dia e p95
            source_stats = latency_df.groupby('source')['latency_ms'].agg(['mean', 'count', lambda x: x.quantile(0.95)]).reset_index()
            source_stats.columns = ['source', 'mean', 'count', 'p95']
            source_stats = source_stats.sort_values('mean', ascending=False).head(10)
            
            bar_lat = alt.Chart(source_stats).mark_bar().encode(
                x=alt.X('mean:Q', title='LatÃªncia MÃ©dia (ms)'),
                y=alt.Y('source:N', sort='-x', title='Origem'),
                color=alt.Color('mean:Q', scale=alt.Scale(scheme='reds')),
                tooltip=['source', 'mean', 'p95', 'count']
            )
            st.altair_chart(bar_lat, use_container_width=True)

        st.subheader("EvoluÃ§Ã£o Temporal (Scatter Plot)")
        scatter_lat = alt.Chart(latency_df).mark_circle(size=60).encode(
            x='timestamp:T',
            y='latency_ms:Q',
            color=alt.Color('latency_ms', scale=alt.Scale(scheme='turbo')),
            tooltip=['timestamp', 'source', 'latency_ms']
        ).interactive()
        st.altair_chart(scatter_lat, use_container_width=True)
        
        st.markdown("---")
        st.subheader("ğŸ¢ DetecÃ§Ã£o de Gargalos (Bottlenecks)")
        st.markdown("IdentificaÃ§Ã£o de serviÃ§os ou operaÃ§Ãµes que estÃ£o excedendo o tempo limite aceitÃ¡vel.")
        
        bottleneck_threshold = st.number_input("Limiar de LatÃªncia para Gargalo (ms)", min_value=100, value=1000, step=100, help="LatÃªncias acima deste valor serÃ£o consideradas gargalos.", key="bottleneck_threshold_3")
        
        bottlenecks = cached_detect_bottlenecks(filtered_df, bottleneck_threshold)
        
        if not bottlenecks.empty:
            st.error(f"Detectados {len(bottlenecks)} serviÃ§os com gargalos de performance (> {bottleneck_threshold}ms).")
            st.dataframe(bottlenecks, use_container_width=True)
            
            # Chart for bottlenecks
            chart_bottleneck = alt.Chart(bottlenecks).mark_bar().encode(
                x=alt.X('avg_latency:Q', title='LatÃªncia MÃ©dia (ms)'),
                y=alt.Y('source:N', sort='-x', title='ServiÃ§o'),
                color=alt.Color('slow_count:Q', title='Qtd OcorrÃªncias', scale=alt.Scale(scheme='orangered')),
                tooltip=['source', 'avg_latency', 'max_latency', 'slow_count']
            ).properties(title="Top Gargalos por LatÃªncia MÃ©dia")
            
            st.altair_chart(chart_bottleneck, use_container_width=True)
        else:
            st.success(f"Nenhum gargalo detectado acima de {bottleneck_threshold}ms.")

    else:
        st.info("Nenhum dado de latÃªncia encontrado nos logs filtrados. Certifique-se que seus logs contenham padrÃµes como 'duration=100ms' ou 'time=0.5s'.")

def render_page():
    """
    Renderiza a aba "InteligÃªncia & PrevisÃ£o" com suas sub-abas.
    """
    st.title("ğŸ§  InteligÃªncia & PrevisÃ£o")

    if 'filtered_df' not in st.session_state or st.session_state['filtered_df'].empty:
        st.warning("Dados nÃ£o carregados. Por favor, vÃ¡ para a pÃ¡gina principal e carregue os dados primeiro.")
        return

    filtered_df = st.session_state['filtered_df']
    time_series_df = st.session_state['time_series_df']
    z_score_threshold = st.session_state['z_score_threshold']
    rarity_threshold = st.session_state['rarity_threshold']
    enable_masking = st.session_state['enable_masking']
    
    subtab_ml, subtab_forecast, subtab_alerts, subtab_siem, subtab_latency = st.tabs([
        "ğŸ§  Anomalias (ML)", "ğŸ”® PrevisÃ£o", "ğŸ”” Alertas", "ğŸ›¡ï¸ SeguranÃ§a", "â±ï¸ Performance"
    ])

    with subtab_ml:
        render_ml_sub_tab(filtered_df, time_series_df, z_score_threshold, rarity_threshold, enable_masking)
    with subtab_forecast:
        render_forecast_sub_tab(filtered_df)
    with subtab_alerts:
        render_alerts_sub_tab(filtered_df, enable_masking)
    with subtab_siem:
        render_siem_sub_tab(filtered_df)
    with subtab_latency:
        render_latency_sub_tab(filtered_df)
